{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "7a2344ae-95e0-4493-bbb9-39be75bbbc82",
    "_uuid": "4e1887c1-ed3c-48be-8780-4757f11486ac",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "94748bae-fdeb-4328-b7df-cd48545fb581",
    "_uuid": "f7b7b1eb-4947-48f9-912f-1b9f4777f015",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_emb, n_heads = 8):\n",
    "        super().__init__()\n",
    "        assert d_emb%n_heads == 0\n",
    "        self.d_emb = d_emb\n",
    "        self.n_heads = n_heads\n",
    "        self.WQ = nn.Linear(d_emb, d_emb, bias = False)\n",
    "        self.WK = nn.Linear(d_emb, d_emb, bias = False)\n",
    "        self.WV = nn.Linear(d_emb, d_emb, bias = False)\n",
    "        self.WO = nn.Linear(d_emb, d_emb, bias = True)\n",
    "    def forward(self, x1, x2 = None, x3 = None, mask = None):\n",
    "        b,s,d = x1.shape\n",
    "        if x2 is None:\n",
    "            x2 = x1\n",
    "        if x3 is None:\n",
    "            x3 = x1\n",
    "        s_enc = x2.shape[1]\n",
    "        q = self.WQ(x1)\n",
    "        k = self.WK(x2)\n",
    "        v = self.WV(x3)\n",
    "        Q = q.view(b, s, self.n_heads, self.d_emb//self.n_heads).permute(0,2,1,3)\n",
    "        K = k.view(b, s_enc, self.n_heads, self.d_emb//self.n_heads).permute(0,2,1,3)\n",
    "        V = v.view(b, s_enc, self.n_heads, self.d_emb//self.n_heads).permute(0,2,1,3)\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2,-1))/((self.d_emb//self.n_heads)**0.5)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == False, -1e9)\n",
    "        attn_weights = torch.softmax(attn_scores, dim = -1)\n",
    "        output = torch.matmul(attn_weights, V).transpose(1,2).contiguous().view(b, s, d)\n",
    "        output = self.WO(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if decode is True:\n",
    "#     dec_mask = torch.ones(s,s)\n",
    "#     dec_mask = torch.triu(dec_mask, diagonal = 1).unsqueeze(0).unsqueeze(1)\n",
    "#     dec_mask = ((dec_mask==0)*1).to(attn_scores.device)\n",
    "#     attn_scores = attn_scores.masked_fill(dec_mask == 0, float(\"-inf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "aacae68f-e66b-4135-933b-44e1b3b6c2d5",
    "_uuid": "2b99e356-7e5e-4497-b5c7-f9352f52b4e1",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0086, -0.0743,  0.0080,  ..., -0.0151,  0.0093, -0.0310],\n",
       "         [ 0.0384, -0.0666,  0.0039,  ...,  0.0290,  0.0526, -0.0432],\n",
       "         [ 0.0269, -0.0577,  0.0205,  ..., -0.0297, -0.0066, -0.0101],\n",
       "         ...,\n",
       "         [ 0.0114, -0.0682,  0.0135,  ..., -0.0151,  0.0052, -0.0342],\n",
       "         [ 0.0114, -0.0682,  0.0135,  ..., -0.0151,  0.0052, -0.0342],\n",
       "         [ 0.0114, -0.0682,  0.0135,  ..., -0.0151,  0.0052, -0.0342]],\n",
       "\n",
       "        [[-0.0423, -0.1515,  0.0534,  ...,  0.0307, -0.0512, -0.1718],\n",
       "         [-0.0365, -0.1598,  0.0988,  ...,  0.0236, -0.0788, -0.1285],\n",
       "         [-0.0176, -0.1429,  0.0959,  ...,  0.0194, -0.0593, -0.1364],\n",
       "         ...,\n",
       "         [-0.0145, -0.1519,  0.0583,  ...,  0.0187, -0.0773, -0.1305],\n",
       "         [-0.0145, -0.1519,  0.0583,  ...,  0.0187, -0.0773, -0.1305],\n",
       "         [-0.0145, -0.1519,  0.0583,  ...,  0.0187, -0.0773, -0.1305]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha = MultiHeadAttention(512, 8)\n",
    "x = torch.randn(2,30,512)\n",
    "x = F.pad(x, (0,0,0,20))\n",
    "mask = torch.ones(2,1,1,30)\n",
    "mask = F.pad(mask, (0,20))\n",
    "mha(x, mask = mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "05aa3d0b-1c45-46cf-b3eb-91105d16e55a",
    "_uuid": "c7fdb54a-9992-4469-bbd1-ebfdab9f0f4e",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class FeedForwardLayer(nn.Module):\n",
    "    def __init__(self, d_emb, upsample_factor = 4):\n",
    "        super().__init__()\n",
    "        self.d_emb = d_emb\n",
    "        self.upsample_factor = upsample_factor\n",
    "        self.linear1 = nn.Linear(d_emb, upsample_factor*d_emb)\n",
    "        self.linear2 = nn.Linear(upsample_factor*d_emb, d_emb)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, X):\n",
    "        out1 = self.relu(self.linear1(X))\n",
    "        return self.linear2(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "e97ff156-32b6-4405-8ba6-a7bc92f5fb05",
    "_uuid": "46901114-634b-4d3c-9ea0-a5a9dfadfb7b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 512])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn = FeedForwardLayer(512)\n",
    "ffn(torch.randn(2,5,512)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "111b5f4e-938b-4397-b46d-5c7f17c70c8a",
    "_uuid": "7472284b-1b1b-4089-b75f-35d6dd75bd87",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class EncoderAttentionBlock(nn.Module):\n",
    "    def __init__(self, d_emb, n_heads = 8, upsample_factor = 4):\n",
    "        super().__init__()\n",
    "        self.d_emb = d_emb\n",
    "        self.n_heads = n_heads\n",
    "        self.upsample_factor = upsample_factor\n",
    "        self.ln1 = nn.LayerNorm(d_emb)\n",
    "        self.ln2 = nn.LayerNorm(d_emb)\n",
    "        self.multihead = MultiHeadAttention(self.d_emb, self.n_heads)\n",
    "        self.feedforward = FeedForwardLayer(self.d_emb, self.upsample_factor)\n",
    "        self.dropout1 = nn.Dropout(p=0.1)\n",
    "        self.dropout2 = nn.Dropout(p=0.1)\n",
    "    def forward(self, X, mask = None):\n",
    "        out1 = self.dropout1(self.multihead(X, mask = mask))\n",
    "        out1 = out1 + X\n",
    "        ln_out1 = self.ln1(out1)\n",
    "        out2 = self.dropout2(self.feedforward(ln_out1))\n",
    "        out2 = out2 + ln_out1\n",
    "        ln_out2 = self.ln2(out2)\n",
    "        return ln_out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "61cda431-021d-4608-8dd6-f0700dd07d4e",
    "_uuid": "49f61a2b-0690-4ef5-a6c7-50bbbc7055f7",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_attn = EncoderAttentionBlock(512)\n",
    "enc_attn(torch.randn(2,5,512)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "a378f8fc-b9ce-4b06-a54f-9bc4b5b6fd41",
    "_uuid": "0fd528d0-b42d-4c74-a3ed-87da20dab404",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_emb, n_layers = 6, n_heads = 8, upsample_factor = 4):\n",
    "        super().__init__()\n",
    "        self.d_emb = d_emb\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.upsample_factor = upsample_factor\n",
    "        self.layers = nn.ModuleList([EncoderAttentionBlock(d_emb, n_heads=n_heads, upsample_factor=upsample_factor) \n",
    "        for _ in range(n_layers)])\n",
    "    def forward(self, X, mask = None):\n",
    "        for layer in self.layers:\n",
    "            X = layer(X, mask = mask)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "94127c02-9fc7-4138-84d0-2e1d2a625126",
    "_uuid": "dddc8b40-af64-4cc4-8bb6-cc92f1f22efc",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = Encoder(512)\n",
    "enc(torch.randn(2,5,512)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "3fc5d87b-4bfc-4313-b32e-78bfd0fcdaf2",
    "_uuid": "62e5c7e2-504a-4da9-b46e-325b9918aa85",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class DecoderAttentionBlock(nn.Module):\n",
    "    def __init__(self, d_emb, n_heads = 8, upsample_factor = 4):\n",
    "        super().__init__()\n",
    "        self.d_emb = d_emb\n",
    "        self.n_heads = n_heads\n",
    "        self.upsample_factor = upsample_factor\n",
    "        self.masked_self_attn = MultiHeadAttention(self.d_emb, self.n_heads)\n",
    "        self.cross_attn = MultiHeadAttention(self.d_emb, self.n_heads)\n",
    "        self.feedforward = FeedForwardLayer(self.d_emb, self.upsample_factor)\n",
    "        self.ln1 = nn.LayerNorm(self.d_emb)\n",
    "        self.ln2 = nn.LayerNorm(self.d_emb)\n",
    "        self.ln3 = nn.LayerNorm(self.d_emb)\n",
    "        self.dropout1 = nn.Dropout(p = 0.1)\n",
    "        self.dropout2 = nn.Dropout(p = 0.1)\n",
    "        self.dropout3 = nn.Dropout(p = 0.1)\n",
    "    def forward(self, X, encoder_output, enc_mask = None, dec_mask = None):\n",
    "        out1 = self.masked_self_attn(X, mask = dec_mask)\n",
    "        out1 = self.dropout1(out1) + X\n",
    "        ln_out1 = self.ln1(out1)\n",
    "        out2 = self.cross_attn(ln_out1, x2 = encoder_output, x3 = encoder_output, mask = enc_mask)\n",
    "        out2 = self.dropout2(out2) + ln_out1\n",
    "        ln_out2 = self.ln2(out2)\n",
    "        out3 = self.feedforward(ln_out2)\n",
    "        out3 = self.dropout3(out3) + ln_out2\n",
    "        ln_out3 = self.ln3(out3)\n",
    "        return ln_out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "d78e5073-99ca-4380-9767-7eb1ac3fb58c",
    "_uuid": "00a93636-bd24-443d-a228-f3373bbcad95",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d_emb, n_layers = 6, n_heads = 8, upsample_factor = 4):\n",
    "        super().__init__()\n",
    "        self.d_emb = d_emb\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.upsample_factor = upsample_factor\n",
    "        self.layers = nn.ModuleList([DecoderAttentionBlock(d_emb, n_heads = n_heads, upsample_factor = upsample_factor)\n",
    "                                    for _ in range(n_layers)])\n",
    "    def forward(self, X, encoder_output, enc_mask = None, dec_mask = None):\n",
    "        for layer in self.layers:\n",
    "            X = layer(X, encoder_output, enc_mask = enc_mask, dec_mask = dec_mask)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "2d8681f8-589d-4890-b8ef-a9cf2b19f9f6",
    "_uuid": "08dfb585-c767-4955-aa65-8e7bec84e7a4",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 512])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec = Decoder(512)\n",
    "dec(torch.randn(2,5,512), torch.randn(2,5,512)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "dc6c2cc8-176c-43b8-8650-60b8a813fd26",
    "_uuid": "d7bc1fe6-8e05-45bc-a0d8-9602785d95ee",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_emb, max_len):\n",
    "        super().__init__()\n",
    "        self.d_emb = d_emb\n",
    "        self.max_len = max_len\n",
    "        pe = torch.zeros(self.max_len, self.d_emb)\n",
    "        for pos in range(self.max_len):\n",
    "            for i in range(self.d_emb):\n",
    "                if i%2 == 0:\n",
    "                    pe[pos][i] = torch.sin(torch.tensor(pos/((10000)**((2*i)/self.d_emb))))\n",
    "                else:\n",
    "                    pe[pos][i] = torch.cos(torch.tensor(pos/((10000)**((2*i)/self.d_emb))))\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "    def forward(self, X):\n",
    "        X = X + self.pe[:X.size(1)]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "c662dc4a-6543-4238-8588-e9bc0582e270",
    "_uuid": "46c6aa2b-85b8-4b3a-9cc4-89854e5614f0",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_emb, vocab_size, max_len, n_layers = 6, n_heads = 8, upsample_factor = 4):\n",
    "        super().__init__()\n",
    "        self.d_emb = d_emb\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.max_len = max_len\n",
    "        self.upsample_factor = upsample_factor\n",
    "        self.enc = Encoder(self.d_emb, n_layers = self.n_layers, n_heads = self.n_heads, upsample_factor = self.upsample_factor)\n",
    "        self.dec = Decoder(self.d_emb, n_layers = self.n_layers, n_heads = self.n_heads, upsample_factor = self.upsample_factor)\n",
    "        self.embed_layer = nn.Embedding(vocab_size, d_emb)\n",
    "        self.pe = PositionalEncoding(d_emb, max_len)\n",
    "        self.out_linear = nn.Linear(d_emb, vocab_size)\n",
    "        self.embed_layer.weight = self.out_linear.weight\n",
    "        self.dropout1 = nn.Dropout(p = 0.1)\n",
    "        self.dropout2 = nn.Dropout(p = 0.1)\n",
    "    def forward(self, X, y, temperature = 1.0, enc_mask = None, dec_mask = None):\n",
    "        enc_embeds = self.embed_layer(X)*(self.d_emb**0.5)\n",
    "        dec_embeds = self.embed_layer(y)*(self.d_emb**0.5)\n",
    "        enc_embeds = self.dropout1(self.pe(enc_embeds))\n",
    "        dec_embeds = self.dropout2(self.pe(dec_embeds))\n",
    "        enc_output = self.enc(enc_embeds, mask = enc_mask)\n",
    "        dec_output = self.dec(dec_embeds, enc_output, enc_mask = enc_mask, dec_mask = dec_mask)\n",
    "        dec_output = self.out_linear(dec_output)\n",
    "        return dec_output/temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "7fc7eef0-9505-476b-bb3f-d260ae0d393d",
    "_uuid": "3f3840d8-be02-46d3-afa7-05729ee6ed98",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(512, 512, 5)\n",
    "X = torch.randint(0, 100, (2, 5), dtype=torch.int64)\n",
    "y = torch.randint(0, 100, (2, 5), dtype=torch.int64)\n",
    "output = transformer(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "6d8ac5a5-fb33-4d7d-99fd-61cadbde3ed2",
    "_uuid": "8c624636-91d4-4a1d-8f05-e8365a5d2e40",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "6fb3a924-5761-4796-aad2-523522c28bbc",
    "_uuid": "6b61de6f-6bc2-4af1-9607-b8783256c552",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 'Two young, White males are outside near many bushes.', 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'}\n"
     ]
    }
   ],
   "source": [
    "# total_dataset = load_dataset(\"wmt14\", \"fr-en\", split=\"train\")\n",
    "total_dataset = load_dataset('bentrevett/multi30k', split = \"train\")\n",
    "print(total_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = total_dataset.shuffle(seed = 42).select(range(100000))\n",
    "dataset = total_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "3adbdeb8-6d56-43fe-a03a-153755b55300",
    "_uuid": "26caaa60-14d6-4c0b-abff-b87540b09c86",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Two young, White males are outside near many bushes.',\n",
       " 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "_cell_guid": "2dc0c2bf-836d-464f-b6db-7c3ffa541ccb",
    "_uuid": "bd7f2e62-eaca-48fc-98e4-ad99cfcee677",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd7f91037cc4b2784f563f08b45c24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\",\n",
    "                                         errors = 'replace',\n",
    "                                         unk_token = '<UNK>',\n",
    "                                         bos_token = '<SOS>',\n",
    "                                         eos_token = '<EOS>',\n",
    "                                         pad_token = '<PAD>',\n",
    "                                         )\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    eng_sentences = [\"<SOS>\"+data+\"<EOS>\" for data in batch['en']]\n",
    "    german_sentences = [\"<SOS>\"+data+\"<EOS>\" for data in batch['de']]\n",
    "    dec_tokenized = tokenizer(eng_sentences, padding=\"max_length\", truncation=True, max_length=50)\n",
    "    enc_tokenized = tokenizer(german_sentences, padding=\"max_length\", truncation=True, max_length=50)\n",
    "    return {\n",
    "        \"enc_input_ids\": enc_tokenized[\"input_ids\"],\n",
    "        \"enc_attention_mask\": enc_tokenized[\"attention_mask\"],\n",
    "        \"dec_input_ids\": dec_tokenized[\"input_ids\"],\n",
    "        \"dec_attention_mask\" : dec_tokenized[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "_cell_guid": "05e7180c-e6a5-41e7-a572-b837da9d89bf",
    "_uuid": "11db4b4d-4d84-47e9-a53d-747abd0c5dcf",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class TranslationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_dataset):\n",
    "        self.enc_inputs = [tokenized_datapoint[\"enc_input_ids\"] for tokenized_datapoint in tokenized_dataset]\n",
    "        self.enc_mask = [tokenized_datapoint[\"enc_attention_mask\"] for tokenized_datapoint in tokenized_dataset]\n",
    "        self.dec_inputs = [tokenized_datapoint[\"dec_input_ids\"] for tokenized_datapoint in tokenized_dataset]\n",
    "        self.dec_mask = [tokenized_datapoint[\"dec_attention_mask\"] for tokenized_datapoint in tokenized_dataset]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.enc_inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"enc_inputs\": torch.tensor(self.enc_inputs[idx]),\n",
    "            \"dec_inputs\": torch.tensor(self.dec_inputs[idx]),\n",
    "            \"enc_mask\" : torch.tensor(self.enc_mask[idx]),\n",
    "            \"dec_mask\" : torch.tensor(self.dec_mask[idx]),\n",
    "        }\n",
    "\n",
    "translation_dataset = TranslationDataset(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9*len(translation_dataset))\n",
    "val_size = len(translation_dataset) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26100"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.random.choice(np.arange(len(translation_dataset)), train_size)\n",
    "val_indices = np.array([index for index in np.arange(len(translation_dataset)) if index not in train_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = [translation_dataset[i] for i in train_indices]\n",
    "val_subset = [translation_dataset[i] for i in val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_data_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "_cell_guid": "147e0891-4300-4165-b217-6a732a784f1d",
    "_uuid": "b5eb9a34-49a3-46e8-8365-fcaf605a63f3",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# !pip install torch-adopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.optim import AdamW\n",
    "# from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "# def setup_optimizer_and_scheduler(model, total_steps):\n",
    "#     base_lr = 1e-4\n",
    "#     warmup_steps = total_steps // 10 \n",
    "    \n",
    "#     optimizer = Adam(model.parameters(), \n",
    "#                      lr=base_lr)\n",
    "\n",
    "#     def lr_lambda(current_step):\n",
    "#         if current_step < warmup_steps:\n",
    "#             return float(current_step) / float(max(1, warmup_steps))\n",
    "#         return max(0.0, float(warmup_steps)**-0.5 * min(\n",
    "#             float(current_step)**-0.5,\n",
    "#             float(current_step) * float(warmup_steps)**-1.5\n",
    "#         ))\n",
    "    \n",
    "#     scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "    \n",
    "#     return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class CustomScheduler:\n",
    "    def __init__(self, optimizer, d_model, warmup_steps):\n",
    "        self.optimizer = optimizer\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.step_num = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.step_num += 1\n",
    "        lr = (self.d_model ** -0.5) * min(\n",
    "            self.step_num ** -0.5, self.step_num * (self.warmup_steps ** -1.5)\n",
    "        )\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "_cell_guid": "882b4546-5912-44e6-bb42-ea03f3587a72",
    "_uuid": "b527b459-4e0c-47ea-85cd-e8d7ef853f02",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# from adopt import ADOPT\n",
    "INPUT_DIM = len(tokenizer)\n",
    "OUTPUT_DIM = len(tokenizer)\n",
    "EMB_DIM = 512\n",
    "N_LAYERS = 6\n",
    "N_HEADS = 8\n",
    "FF_DIM = 2048\n",
    "DROPOUT = 0.1\n",
    "MAX_LEN = 100\n",
    "warmup_steps = 4000\n",
    "\n",
    "model = Transformer(EMB_DIM, OUTPUT_DIM, MAX_LEN, n_layers=N_LAYERS, n_heads=N_HEADS, upsample_factor=FF_DIM//EMB_DIM).to(device)\n",
    "# total_steps = 5 * len(train_data_loader)\n",
    "# optimizer, lr_scheduler = setup_optimizer_and_scheduler(model, total_steps)\n",
    "# optimizer = optim.Adam(model.parameters(), lr = 5e-4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-9, lr = 1e-4)\n",
    "scheduler = CustomScheduler(optimizer, EMB_DIM, warmup_steps)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "_cell_guid": "ebfcc100-de73-4971-bcfd-7b27819392e2",
    "_uuid": "832f5ec8-d04f-4ded-b8fd-e12cf1191724",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_mask(src, tgt):\n",
    "    src_mask = (src != tokenizer.pad_token_id).unsqueeze(1).unsqueeze(2)\n",
    "    tgt_mask = (tgt != tokenizer.pad_token_id).unsqueeze(1).unsqueeze(3)\n",
    "    seq_length = tgt.size(1)\n",
    "    causal_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device)\n",
    "    tgt_mask = tgt_mask & causal_mask\n",
    "    return src_mask, tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "_cell_guid": "d1264bc3-5da9-4b57-ba8b-9b2705c6e598",
    "_uuid": "5ec09b17-d31a-4437-8f3b-3212710aca94",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True, False, False,  ..., False, False, False],\n",
       "         [ True,  True, False,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         ...,\n",
       "         [ True,  True,  True,  ...,  True, False, False],\n",
       "         [ True,  True,  True,  ...,  True,  True, False],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True]]], device='cuda:0')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_data = torch.randint(1, 5000, (32, 50)).to(device)\n",
    "tgt_data = torch.randint(1, 5000, (32, 50)).to(device)\n",
    "generate_mask(src_data, tgt_data)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def initial_cost(model, data_loader):\n",
    "#     model.eval()\n",
    "#     epoch_loss = 0\n",
    "#     with torch.inference_mode():\n",
    "#         for batch in tqdm(data_loader):\n",
    "#             src = batch['enc_inputs'].to(device)\n",
    "#             trg = batch['dec_inputs'].to(device)\n",
    "#             trg_in = trg.clone()\n",
    "#             # trg_in[trg_in == tokenizer.eos_token_id] = tokenizer.pad_token_id\n",
    "#             trg_in1 = torch.tensor([token for token in trg_in[0] if token!=tokenizer.pad_token_id]).unsqueeze(0).to(device)\n",
    "#             trg_out = torch.tensor([token for token in trg[0] if token!=tokenizer.pad_token_id]).unsqueeze(0)\n",
    "#             trg_out = trg_out[:,1:].clone().to(device)\n",
    "#             enc_mask, dec_mask = generate_mask(src, trg_in1)\n",
    "#             output = model(src, trg_in1[:,:-1])\n",
    "#             # print(output.shape)\n",
    "#             output_dim = output.shape[-1]\n",
    "#             output = output.contiguous().view(-1, output_dim)\n",
    "#             trg_out = trg_out.contiguous().view(-1)\n",
    "#             loss = criterion(output, trg_out)\n",
    "#             epoch_loss += loss.item() / len(data_loader)\n",
    "#             del batch\n",
    "#     return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_cost(model, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(test_sentence):\n",
    "    model.eval()\n",
    "    src = tokenizer.encode(test_sentence, padding = 'max_length', max_length = 50, truncation = True, return_tensors = 'pt').to(device)\n",
    "    enc_mask = (src!=tokenizer.pad_token_id).unsqueeze(1).unsqueeze(2)\n",
    "    out = [tokenizer.bos_token_id]\n",
    "    with torch.inference_mode():\n",
    "        src = model.embed_layer(src)\n",
    "        enc_output = model.enc(src, mask = enc_mask)\n",
    "        for _ in range(model.max_len):\n",
    "            out_embed = (model.embed_layer(torch.tensor(out).to(device)).to(device)).unsqueeze(0)*(model.d_emb**0.5)\n",
    "            tgt = torch.tensor(out).unsqueeze(0)\n",
    "            seq_length = tgt.size(1)\n",
    "            tgt_mask = (tgt != tokenizer.pad_token_id).unsqueeze(1).unsqueeze(3).to(device)\n",
    "            causal_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device)\n",
    "            tgt_mask = (tgt_mask & causal_mask).to(device)\n",
    "            dec_output = model.dec(out_embed, enc_output, enc_mask = enc_mask, dec_mask = tgt_mask)\n",
    "            dec_output = F.softmax(model.out_linear(dec_output), dim = -1)\n",
    "            next_token = dec_output[:,-1,:].argmax(dim = -1).item()\n",
    "            out.append(next_token)\n",
    "\n",
    "            if next_token == tokenizer.eos_token_id:\n",
    "                break\n",
    "        out_sentence = tokenizer.decode(out, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        return out_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = 1e-3, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "_cell_guid": "e5fec440-4a13-4614-8e7a-a5933b7c48ae",
    "_uuid": "78c23b08-8688-4ba1-8bd6-e3cb1e99697a",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, data_loader, optimizer, scheduler, criterion, clip=1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_data_loader):\n",
    "        src = batch['enc_inputs'].to(device)\n",
    "        trg = batch['dec_inputs'].to(device)\n",
    "\n",
    "        trg_in = trg.clone()    \n",
    "        trg_in = trg_in[:,:-1]\n",
    "        trg_out = trg[:,1:].clone()\n",
    "        enc_mask, dec_mask = generate_mask(src, trg_in)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg_in, enc_mask = enc_mask, dec_mask = dec_mask)\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        trg_out = trg_out.contiguous().view(-1)\n",
    "\n",
    "        loss = criterion(output, trg_out)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = clip)\n",
    "\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        epoch_loss += loss.item()\n",
    "        # batch = batch.detach()\n",
    "        del batch, trg_in, trg_out, enc_mask, dec_mask, output\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    #lr_scheduler.step()\n",
    "    return epoch_loss / len(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('/kaggle/input/transformer-2epoch/transformer.pth', weights_only = True)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "_cell_guid": "b45affac-43f2-42af-b124-12e7147049ea",
    "_uuid": "b847c9bd-7e82-4fad-a9f7-e2f05a3bdec0",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95db00fd9e294b558308f35d3b5a918a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8716c43d042441db94c9cd33ec09ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1632 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 4.306\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81be2b1914ae47caa9e64d0c261d2d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1632 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "Train Loss: 4.287\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32dbe8ac48c42d8866e16d97dec0120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1632 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      "Train Loss: 4.279\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d4e2e921664f1899f0640ff438870d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1632 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "Train Loss: 4.272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b24f02308f4fd6a20fb67f532e607c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1632 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      "Train Loss: 4.264\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "CLIP = 1\n",
    "\n",
    "for epoch in tqdm(range(N_EPOCHS)):\n",
    "    train_loss = train_model(model, train_data_loader, optimizer, scheduler, criterion, CLIP)\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    print(f\"Train Loss: {train_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    # 'scheduler_state_dict': lr_scheduler.state_dict()\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'transformer2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = tokenizer.decode(data['enc_inputs'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<SOS>People gathered around at an outdoor event.<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(data['dec_inputs'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS>Mehrere Personen bei einer Freiluftveranstaltung.<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n"
     ]
    }
   ],
   "source": [
    "print(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = inference(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation():\n",
    "    model.eval()\n",
    "    out_dict = {}\n",
    "    out_dict['input'] = []\n",
    "    out_dict['target'] = []\n",
    "    out_dict['output'] = []\n",
    "    with torch.inference_mode():\n",
    "        for batch in tqdm(val_data_loader):\n",
    "            src = batch['enc_inputs']\n",
    "            trg = batch['dec_inputs']\n",
    "            trg = tokenizer.decode(trg[0])\n",
    "            test_sentence = tokenizer.decode(src[0])\n",
    "            out_dict['input'].append(test_sentence)\n",
    "            out_dict['target'].append(trg)\n",
    "            output = inference(test_sentence)\n",
    "            out_dict['output'].append(output)\n",
    "            del batch, src, trg, test_sentence, output\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-02-04T09:20:13.145542Z",
     "iopub.status.idle": "2025-02-04T09:20:13.145921Z",
     "shell.execute_reply": "2025-02-04T09:20:13.145762Z"
    }
   },
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('/kaggle/input/transformer-2epoch/transformer.pth', weights_only = True)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.config.clear_cache() "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6592802,
     "isSourceIdPinned": false,
     "sourceId": 10656532,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
